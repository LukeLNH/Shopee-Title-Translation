{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom transformers import TFAutoModelWithLMHead, TFXLMRobertaForMaskedLM, TFXLMRobertaForTokenClassification, AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('roberta-base') #'jplu/tf-xlm-roberta-base'\n\nmodel = TFXLMRobertaForMaskedLM.from_pretrained('roberta-base')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_len = 10\nbatch_size = 10\nepochs = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/shopee-code-league-20/_DS_Title_Translation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shopee_data = pd.concat([pd.read_csv(\"dev_tcn.csv\").drop(columns = [\"split\"]), pd.read_csv(\"dev_en.csv\")], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shopee_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(tokenizer.batch_encode_plus(shopee_data.text[:100], return_attention_masks=False, pad_to_max_length= True, max_length= seq_len)['input_ids'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array(tokenizer.batch_encode_plus(shopee_data.translation_output[:100], return_attention_masks=False, pad_to_max_length= True, max_length= seq_len)['input_ids'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y \n#We see that regardless of the encoded language, te start token is 0, and the end token is 2\n#In our code, if we want to predict one word of the sentence at a time instead of the entire sentence at once,\n#we just need to search for when the model outputs 2, and that will be the end of our sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_res = model.predict(X[0].reshape((1,seq_len)))[0] \n#when predicting for a single value, must reshape the array to (1, seq_len) so that the model doesnt see shape (seq_len,) and assume we are\n    #predicting seq_len different sentences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_res.shape #shape = (batch_size, seq_len, vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(test_res, axis = 2) #This line of code returns the output predictions. We can use the tokenizer to decode this","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (tf.data.Dataset\n                     .from_tensor_slices((X_train, y_train))\n                     .repeat()\n                     .shuffle(100)\n                     .batch(batch_size))\n\ntest_dataset = (tf.data.Dataset\n                     .from_tensor_slices((X_test, y_test))\n                     .shuffle(100)\n                     .batch(batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_dataset, steps_per_epoch = X_train.shape[0], epochs = epochs, validation_data = test_dataset)\n#currently the code is throwing 'UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume \n    #a large amount of memory.'\n    \n    #Note quite sure why this is happening, seems this is an internal problem of Hugging Face Transformers' implementation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It would be easy to add more sentences, increase the seq_len, etc. The code for how to make predictions has also been demonstrated.\n    #Using the model itself as a direct translator isn't hard per se, and training for sufficiently long should yield a decent translator.\n    #That being said, more optimization is necessary to build a better translator.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sentence = X_test[0]\npred = model.predict(sample_sentence.reshape((1,seq_len)))[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoded_pred = tokenizer.decode(np.argmax(pred, axis = 2).reshape((seq_len,)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoded_pred #The output doesn't make sense right now since I set seq_len to only 10 and only used 100 samples for code demonstration\n    #purposes. As we can see, this line of code is how we would get the decoded predictions.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}